# ğŸ›’ Amazon Web Scraper using Selenium & BeautifulSoup

This project is a Python-based web scraper that extracts product information (title, price, and link) from **Amazon.in** using **Selenium** and **BeautifulSoup**, and saves the data to a structured **CSV file**. It's ideal for practicing web scraping and data handling in Python.  

## ğŸš€ Features

- Extracts **product title**, **price**, and **link**
- Handles **missing data gracefully**
- Saves data to a CSV file for easy access
- Fully automated and easy to run

## ğŸ“‚ Folder Structure

```bash
ğŸ“ Selenium Python Project/
â”œâ”€â”€ ğŸ“ data/ # Folder containing saved HTML files from Amazon
â”œâ”€â”€ ğŸ“„ collect.py # Main script to parse HTML and save CSV
â”œâ”€â”€ ğŸ“„ requirements.txt # List of dependencies
â”œâ”€â”€ ğŸ“„ data.csv # Output file with extracted data
```


## âš™ï¸ How It Works

1. You save Amazon product page HTML files in the `data/` folder.
2. The script parses each file, extracts the product info, and stores it in a dictionary.
3. All extracted data is saved to `data.csv`.

---

## ğŸ§ª Requirements

- Python 3.x
- Selenium
- BeautifulSoup (bs4)
- Pandas

Install dependencies using:

```bash
pip install -r requirements.txt
```
Or manually:

```bash
pip install selenium beautifulsoup4 pandas
```

---

## â–¶ï¸ How to Run
1. Clone this repo:
```bash
git clone https://github.com/AdithyaSalian23/amazon-web-scraper
cd amazon-web-scraper
```
2. Place your Amazon HTML files inside the data/ folder.
   
3. Run the scraper:
```bash
python collect.py
```
4. Check the generated data.csv file for the output. ğŸ‰

---

## ğŸ§  Skills Used
ğŸ Python

ğŸŒ Selenium

ğŸœ BeautifulSoup

ğŸ“Š Pandas

ğŸ’¾ Git & GitHub

---

## ğŸ“„ License
This project is open-source and free to use under the [MIT License](https://opensource.org/licenses/MIT).
